# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-04.csv`
- Размер: 25000 строк, 62 столбца
- Целевая переменная: 'target' (бинарная классификация, классы: 0: 95% ; 1: 5%)
- Признаки: 60 числовых признаков** (`f01`–`f60`, типы в основном `float64`), категориальных-подобных признаков не обнаружено, пропусков нет.

## 2. Protocol

- Разбиение: train/test** с долей теста **25%** (`test_size=0.25`), фиксированный `random_state=42`, стратификация по целевой переменной (`stratify=y`).
- Подбор: CV на train через `StratifiedKFold` с **3 фолдами** (`shuffle=True`, `random_state=42`) для ускорения. Согласованный критерий подбора: **ROC-AUC** (уместен для бинарной задачи и не зависит от выбранного порога).
- Метрики: accuracy, F1 (для бинарной задачи), ROC-AUC. Дополнительно для дисбаланса считали Average Precision и строили PR-кривую, так как при редком положительном классе PR-метрики лучше отражают качество.

## 3. Models

DummyClassifier — базовая модель для сравнения, всегда прогнозирует наиболее частый класс.
LogisticRegression — логистическая регрессия с масштабированием StandardScaler (Pipeline) и class_weight="balanced".
DecisionTreeClassifier — решающее дерево с контролем сложности (подбор max_depth, min_samples_leaf).
RandomForestClassifier — случайный лес (n_estimators=150 для скорости), подбор max_depth, min_samples_leaf, max_features, использовано class_weight="balanced_subsample".
HistGradientBoostingClassifier — бустинг деревьев, подбор learning_rate, max_depth, max_iter.
Гиперпараметры для моделей недели подбирались через GridSearchCV с 3-фолдовой CV только на train.

## 4. Results

Метрики на test (финальная оценка):

Boosting_HGB (best):
- accuracy: 0.97648
- f1: 0.691824
- ROC-AUC: 0.905049
- Average Precision: 0.771249

RandomForest:
- accuracy: 0.96848
- f1: 0.527578
- ROC-AUC: 0.897551
- Average Precision: 0.781438

LogisticRegression:
- accuracy: 0.77920
- f1: 0.257266
- ROC-AUC: 0.841861
- Average Precision: 0.457002

DecisionTree:
- accuracy: 0.87712
- f1: 0.366337
- ROC-AUC: 0.831763
- Average Precision: 0.333141

DummyClassifier:
- accuracy: 0.95088
- f1: 0.000000
- ROC-AUC: 0.500000
- Average Precision: 0.049120

Победитель: Boosting_HGB, так как он показал наилучший результат по ROC-AUC на CV(train) (best_cv_score≈0.897). Далее модель была один раз оценена на test: ROC-AUC≈0.905 и F1≈0.692, что важно для качества по редкому классу

## 5. Analysis

- Устойчивость: отдельные 5 прогонов с разными random_state не выполнялись (опциональная часть). В рамках выполненного протокола устойчивость частично обеспечивается тем, что подбор параметров делался через StratifiedKFold (3 фолда) на train.
- Ошибки: Confusion Matrix для Boosting_HGB показала: TN=5938, FP=5, FN=142, TP=165. Модель почти не даёт ложных срабатываний (FP очень мало), но часть объектов положительного класса всё ещё пропускается (FN), что типично для задач с дисбалансом. Поэтому дополнительно анализируются ROC/PR-кривые и метрики F1/AP.
- Интерпретация: Permutation importance (top-15) для Boosting_HGB показала, что наиболее важные признаки (по убыванию): f25, f54, f58, f47, f33, f53, f13, f38, f11, f08, f04, f41, f52, f15, f43.
Выводы: признак f25 даёт наибольший вклад в качество модели, далее идёт группа признаков f54/f58/f47 и т.д. Это указывает, что модель опирается на ограниченный набор наиболее информативных признаков.

## 6. Conclusion

Деревья решений склонны к переобучению, поэтому важен контроль сложности (max_depth, min_samples_leaf).
Ансамбли (Random Forest и Boosting) существенно улучшают качество по сравнению с линейным baseline и одиночным деревом, особенно в задачах с дисбалансом.
Для fraud-like задач одной accuracy недостаточно: более информативны ROC-AUC, F1 и PR/average_precision, а также анализ confusion matrix.
Permutation importance помогает интерпретировать модель и выделить признаки, которые сильнее всего влияют на предсказания.
Честный ML-протокол (фиксированный train/test + CV только на train + test один раз для финальной оценки) даёт реалистичную оценку качества и защищает от “подглядывания” в test.
