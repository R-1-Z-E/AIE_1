# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000, 9)
- Признаки: 8 числовых признаков (f01–f08) + sample_id (идентификатор)
- Пропуски: нет
- "Подлости" датасета: разные шкалы признаков + шумовые признаки (без масштабирования distance-based методы могут давать смещённые результаты)

### 1.2 Dataset B

- Файл: S07-hw-dataset-02.csv (в ноутбуке: hw07_ds2)  
- Размер: (8000, 4)  
- Признаки: 3 числовых (x1, x2, z_noise) + sample_id (идентификатор)  
- Пропуски: нет  
- "Подлости" датасета: нелинейная структура + выбросы/шум (KMeans часто проигрывает, DBSCAN может быть уместнее)

### 1.3 Dataset C

- Файл: S07-hw-dataset-03.csv (в ноутбуке: hw07_ds3)  
- Размер: (15000, 5)  
- Признаки: 4 числовых (x1, x2, f_corr, f_noise) + sample_id (идентификатор)  
- Пропуски: нет  
- "Подлости" датасета: кластеры разной плотности + фоновый шум (DBSCAN чувствителен к eps, KMeans может быть компромиссным решением)

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: 
  - Разделял sample_id и X (в признаки sample_id не включал).
  - Для числовых признаков: `SimpleImputer(strategy="median")` + `StandardScaler()`.
  - Категориальных признаков в выбранных датасетах нет, поэтому кодирование не применялось.
  - PCA использовалась только для визуализации (2D scatter), не для обучения моделей.
- Поиск гиперпараметров:
  - KMeans: перебор `k` в диапазоне **2…20**, фиксировал `random_state=42`, для финального решения `n_init=10` (на этапе подбора можно было меньше для ускорения).
  - DBSCAN: перебор сетки по `eps` и `min_samples` (min_samples ∈ {3,5,10}, eps по сетке в разумном диапазоне), дополнительно контролировалась доля шума (label = -1).
  - Основной ориентир: **silhouette_score** (выше — лучше).
  - Для DBSCAN дополнительно учитывалась доля шума: при прочих равных предпочтительнее конфигурации с меньшим `noise_share` (чтобы решение не превращалось в “почти всё шум”).
- Метрики: 
  - `silhouette_score` (выше лучше)
  - `davies_bouldin_score` (ниже лучше)
  - `calinski_harabasz_score` (выше лучше)
  - Для DBSCAN:
    - явно считалась доля шума `noise_share`
    - метрики считались по **non-noise** точкам (labels != -1), чтобы оценка отражала качество кластеров, а не “наказание” за выбросы
- Визуализация: 
  - PCA(2D) scatter по лучшему решению для каждого датасета.
  - Дополнительные графики подбора параметров:
    - silhouette vs k (KMeans)
    - silhouette vs eps (DBSCAN, для min_samples=5)
  - t-SNE не использовался (опциональная часть).

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Для каждого датасета сравнивались минимум 2 алгоритма:

- KMeans:
  - подбирался `n_clusters (k) = 2…20`
  - фиксировались `random_state=42` и `n_init` (финально n_init=10)

- DBSCAN:
  - подбирались `eps` и `min_samples` (min_samples ∈ {3,5,10})
  - отдельно фиксировалась доля шума (noise_share), метрики считались на non-noise точках

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: KMeans (k=2, random_state=42, n_init=10)
- Метрики (silhouette / DB / CH): 0.519 / ~0.685 / ~11786
- Если был DBSCAN: DBSCAN перебирался, но существенного выигрыша по метрикам/интерпретации не дал, поэтому выбран KMeans.
- Коротко: на PCA видны 2 компактных “шарообразных” кластера; после масштабирования KMeans даёт наиболее понятное и стабильное разбиение.

### 4.2 Dataset B

- Лучший метод и параметры: DBSCAN (eps ≈ 0.709, min_samples = 3)
- Метрики (silhouette / DB / CH): 0.329 / 0.5510 / 10.40
- Если был DBSCAN: noise_share ≈ 0.007 (≈0.7% точек). Шум интерпретируется как выбросы/аномалии.  
- Коротко: KMeans максимум давал silhouette 0.3058 (k=2), хуже DBSCAN, датасет с нелинейной структурой и шумом: DBSCAN лучше отражает плотностные группы и отделяет выбросы (noise=-1).

### 4.3 Dataset C

- Лучший метод и параметры: KMeans (k=4, random_state=42, n_init=10) 
- Метрики (silhouette / DB / CH): 0.314 / 1.160 / 6492  
- Если был DBSCAN: DBSCAN перебирался, но качество по silhouette было низким/нестабильным при разных eps (сложно подобрать единый eps при разной плотности).  
- Коротко: при разной плотности и шуме DBSCAN сильно чувствителен к eps, а KMeans с k=4 дал наиболее стабильный компромисс и интерпретируемое разбиение.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Где KMeans "ломается" и почему?
  - На нелинейных структурах и при выраженных выбросах: он оптимизирует “сферические” кластеры по евклидовой геометрии и не умеет помечать выбросы.
  - Пример: hw07_ds2 — KMeans не так хорошо отражает структуру данных.
- Где DBSCAN/иерархическая кластеризация выигрывают и почему?
  - DBSCAN выигрывает на данных с плотностными кластерами и выбросами: умеет выделять произвольные формы и выносить выбросы в noise=-1.
  - Пример: hw07_ds2 — DBSCAN дал лучшее решение с малой долей шума.
- Что сильнее всего влияло на результат (масштабирование, выбросы, плотность, пропуски, категориальные признаки)?
  - Масштабирование (StandardScaler): критично для distance-based методов, особенно при разных шкалах (hw07_ds1).
  - Выбросы/шум: ухудшают KMeans, но естественно обрабатываются DBSCAN (hw07_ds2).
  - Разная плотность: усложняет DBSCAN из-за выбора eps (hw07_ds3).

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка устойчивости: **5 запусков KMeans** на датасете **hw07_ds1** с разными `random_state` и измерение похожести разбиений через **ARI**.
- Результат: **Mean ARI (off-diagonal) = 1.0**.
- Вывод: разбиение полностью устойчивое, что ожидаемо для датасета с хорошо отделимыми “шарообразными” кластерами и выбранным k=2.

### 5.3 Интерпретация кластеров

- Для интерпретации использовались:
  - визуализация PCA(2D) с раскраской по кластерам (понимание геометрии и разделимости),
  - логика алгоритмов (KMeans — центры/“шары”; DBSCAN — плотность и noise).
- Выводы:
  - hw07_ds1: два кластера визуально отделимы → интерпретация как две устойчивые группы объектов.
  - hw07_ds2: DBSCAN выделяет плотную структуру и немного noise → шум можно трактовать как выбросы.
  - hw07_ds3: несколько областей с шумом/разной плотностью → границы не идеальные, поэтому выбрано стабильное разбиение KMeans как компромисс.

## 6. Conclusion

- Масштабирование (StandardScaler) критично для корректной кластеризации distance-based методами.
- Внутренние метрики (silhouette/DB/CH) полезны без истинных меток, но их лучше интерпретировать вместе с визуализацией (PCA).
- KMeans хорош на “шарообразных” кластерах и обычно даёт стабильный результат при фиксированном k.
- DBSCAN подходит для нелинейных форм и выбросов, так как умеет выделять плотные области и помечать шум.
- При разной плотности кластеров DBSCAN чувствителен к eps, и подбор параметров становится ключевой проблемой.
- “Честный” протокол: единый препроцессинг, явный поиск параметров, одинаковые метрики и одинаковая визуализация для сравнения.
